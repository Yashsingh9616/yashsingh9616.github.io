---
 layout: post
 title: Loki
---


**Loki** is a horizontally scalable, highly available, multi-tenant log aggregation system inspired by Prometheus. Unlike other logging systems like Elasticsearch or the ELK stack, Loki is designed to store logs as streams, indexed only by labels (similar to how Prometheus handles metrics), which makes it lightweight and efficient for log storage. 

It is primarily used with **Grafana** to visualize logs and metrics side by side.

### Loki Architecture

Loki's architecture is designed to scale horizontally and consists of the following components:

1. **Loki (Log Aggregator)**
   - Collects logs and stores them in a compressed format without indexing the content of the logs. Only metadata (labels) are indexed.
   
2. **Promtail (Log Shipper)**
   - A client responsible for gathering logs from hosts and sending them to Loki.
   - Works similarly to Logstash or Fluentd in the ELK stack.

3. **Ingester**
   - Receives and compresses log entries and stores them in chunks.
   - Handles writing log data into the storage backend (e.g., S3, GCS, local disk).

4. **Querier**
   - Handles queries from Grafana or other tools, retrieves logs, and serves them to the user.

5. **Distributor**
   - A load-balancing component that routes log data to the ingesters.

6. **Storage Backend**
   - Loki supports various backends like:
     - Object stores (S3, GCS, etc.)
     - Filesystems
     - DynamoDB (for indexes)

### Loki Components Breakdown

1. **Promtail**
   - Promtail is an agent that ships the logs to Loki.
   - It can collect logs from:
     - Files (like `/var/log/*`)
     - Systemd journald
     - Kubernetes pods

2. **Distributor**
   - The first stop for incoming log entries.
   - Responsible for validating logs, adding them to the appropriate stream, and forwarding them to the ingesters.

3. **Ingester**
   - Takes the log data and writes it to the storage.
   - It handles the log ingestion, chunking the logs and saving them in a compressed format.

4. **Querier**
   - Responsible for reading data from the long-term storage when requested.
   - Works in conjunction with the **Ingester** for reading in-memory data.

5. **Storage**
   - Loki’s chunks (log data) are written to a storage backend.
   - The index data is stored in a highly available NoSQL database (e.g., Cassandra, Bigtable, or DynamoDB).

### Loki Workflow

1. **Log Collection**: Logs are gathered by **Promtail** from various sources (systemd, log files, Kubernetes logs).
2. **Log Labeling**: Promtail attaches metadata (labels) to the logs (e.g., `job`, `instance`, `pod`, `container`).
3. **Log Aggregation**: The logs are sent to **Loki**, where the **Distributor** routes them to the **Ingester**.
4. **Storage**: Logs are written in compressed form to the **Storage Backend**.
5. **Log Querying**: **Grafana** queries Loki via the **Querier**, and logs are fetched from the storage or ingesters for visualization.

### Loki Setup Commands and Configuration

#### 1. **Installing Loki**
- You can run Loki using Docker, or as a binary, or in a Kubernetes environment using Helm.

**Docker Example:**
```bash
docker run -d --name=loki -p 3100:3100 grafana/loki:latest
```

#### 2. **Promtail Installation**
Promtail is used to ship logs to Loki.

**Docker Example:**
```bash
docker run -d --name=promtail -v /var/log:/var/log -v /etc/promtail:/etc/promtail grafana/promtail:latest -config.file=/etc/promtail/promtail-config.yaml
```

**Promtail Config Example:**
```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: varlogs
          __path__: /var/log/*.log
```

#### 3. **Grafana Configuration**
- In Grafana, Loki is added as a data source to visualize the logs.
1. Go to **Configuration > Data Sources** in Grafana.
2. Select **Loki** and configure it by providing the URL where Loki is running (e.g., `http://localhost:3100`).

#### 4. **Querying Logs in Grafana**

Loki uses its own **LogQL** query language, which is inspired by Prometheus’ query language (PromQL). Basic LogQL syntax involves filtering logs based on labels.

**Examples**:

1. **View logs from a specific job**:
   ```logql
   {job="varlogs"}
   ```

2. **Filter logs by content**:
   ```logql
   {job="varlogs"} |= "error"
   ```

3. **Count the number of log entries**:
   ```logql
   count_over_time({job="varlogs"}[5m])
   ```

### Loki Commands

1. **Start Loki** (with config file):
   ```bash
   ./loki --config.file=loki-config.yaml
   ```

2. **Run Promtail** (with config file):
   ```bash
   ./promtail --config.file=promtail-config.yaml
   ```

3. **Tail Logs using LogQL** (get logs for the last 5 minutes):
   ```bash
   curl -G 'http://localhost:3100/loki/api/v1/query' --data-urlencode 'query={job="varlogs"}[5m]'
   ```

4. **Loki Config Example**:
   ```yaml
   auth_enabled: false

   server:
     http_listen_port: 3100

   ingester:
     lifecycler:
       ring:
         kvstore:
           store: inmemory
         replication_factor: 1
     chunk_idle_period: 5m
     max_chunk_age: 1h
     chunk_retain_period: 30s
     max_transfer_retries: 0

   schema_config:
     configs:
       - from: 2020-10-24
         store: boltdb-shipper
         object_store: filesystem
         schema: v11
         index:
           prefix: index_
           period: 24h

   storage_config:
     boltdb_shipper:
       active_index_directory: /tmp/loki/boltdb-shipper-active
       cache_location: /tmp/loki/boltdb-shipper-cache
       shared_store: filesystem
     filesystem:
       directory: /tmp/loki/chunks

   limits_config:
     enforce_metric_name: false
     reject_old_samples: true
     reject_old_samples_max_age: 168h

   chunk_store_config:
     max_look_back_period: 0s

   table_manager:
     retention_deletes_enabled: false
     retention_period: 0s
   ```
